{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "qZfMNnOmju8d",
        "outputId": "051a4a7b-ede4-4459-d8f8-0f13ab9be50c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n##Question 1:  What is Logistic Regression, and how does it differ from Linear \\nRegression? \\n\\nLogistic Regression is a statistical / machine‑learning method used to predict categorical outcomes, especially when there are two possible classes (binary classification). It estimates the probability that a given input belongs to one class rather than another (for example, “spam” vs “not spam”, “disease” vs “no disease”). Based on that probability, one can decide a threshold (often 0.5) and assign a class label. It uses features (input variables) to compute how they influence the likelihood of each class.\\n\\nIn contrast, Linear Regression is used when the target/output is continuous (such as house prices, temperature, height). It models a direct linear relationship between input variables and the numerical output: given inputs, it predicts a value on a continuous scale.\\n\\nKey differences:\\n\\nOutput type: Logistic gives probabilities / classes (categorical), Linear gives numerical values (continuous). \\n\\nInterpretation: In Linear Regression, the change in output is directly proportional to changes in input; in Logistic Regression, inputs affect the log‑odds or relative risk, hence indirectly influence the probability of class membership. \\n\\nAssumptions and model fitting: Linear Regression assumes the errors are normally distributed, constant variance (homoscedasticity), etc., and typically uses least squares methods. Logistic Regression does not assume the output is normally distributed; it uses methods like maximum likelihood estimation to find the best parameters. \\n\\n\\n##Question 2: Explain the role of the Sigmoid function in Logistic Regression.\\n\\nPurpose of the Sigmoid in Logistic Regression\\n\\nMapping to Probability Values\\nWhen the model computes a raw score (a weighted sum of features plus a bias), that result can be any real number — positive, negative, large, or small. The sigmoid transforms that into something between 0 and 1. That output can be interpreted as the probability that the input belongs to the positive class. \\n\\nEnabling Decision Making\\nOnce we have a probability, we can pick a threshold (commonly 0.5) to decide whether to assign class “yes/1” or “no/0.” Without the sigmoid, the raw score wouldn’t map cleanly into a probability, and we couldn’t as naturally choose such thresholds. \\n\\nSmooth Transition Around the Boundary\\nThe sigmoid gives a smooth, “S‑shaped” transition from low probability to high probability as the raw score shifts. That means small changes near the decision boundary (where the model is uncertain) lead to gradual change in output. This allows the model to learn in a stable way when changing its parameters. \\n\\nSuitability for Optimization\\nBecause the sigmoid is smooth and differentiable everywhere, it supports gradient‑based optimization. The model’s training process (e.g. maximizing likelihood or minimizing a loss) needs to know how output changes as parameters change. The sigmoid’s smoothness helps compute those gradients reliably.\\n\\n\\n##Question 3: What is Regularization in Logistic Regression and why is it needed? \\n\\nRegularization in Logistic Regression is a technique used to reduce overfitting by constraining or penalizing the magnitude of the model’s parameters (coefficients). It helps the model generalize better to unseen data rather than just memorizing the training examples. \\n\\nWhy Regularization Is Needed\\n\\nModels with many features or those that are very flexible can fit even random noise in the training data. That leads to high performance on training data but poor performance on new/unseen data. This is called overfitting. \\n\\nRegularization prevents the model from relying too heavily on any one feature or giving extremely large weights to some features. That reduces variance in model predictions. \\n\\n\\nIt improves stability: with regularization, small changes in training data or slight noise won’t cause wildly different parameter estimates. This makes the model more robust. \\n\\nHow Regularization Works (Conceptually)\\n\\nEven without going into formulas:\\n\\nIntroduce a penalty or constraint on large parameter values. The model then finds a balance between accurately classifying the training data and keeping its parameters “small” or “simple.” \\n\\nThere are different styles:\\n\\nOne type encourages sparse solutions (making some parameters zero → effectively ignoring less useful features) \\n\\nAnother just “shrinks” all parameters somewhat toward simpler values without necessarily zeroing them out\\n\\n\\n##Question 4: What are some common evaluation metrics for classification models, and \\nwhy are they important? \\n\\nHere are some common evaluation metrics for classification models, and why they matter — all without using equations:\\n\\nCommon Metrics\\n\\nAccuracy\\nMeasures how often the model’s predictions are correct overall (both positive and negative). It is intuitive and widely used. \\n\\nPrecision\\nOf those cases the model predicts as positive, how many are truly positive. Useful when false alarms (false positives) are costly. \\n\\nRecall (Sensitivity)\\nOf all actual positive cases, how many did the model correctly identify. Important when missing positive cases is more serious. \\n\\nF1‑Score\\nA harmonic balancing of precision and recall. It gives a single score that reflects both, helpful especially when classes are imbalanced or when you require a trade‑off between false positives and false negatives. \\n\\nROC‑AUC (Receiver Operating Characteristic – Area Under Curve)\\nConsiders how well the model distinguishes positive and negative classes across different thresholds. It reflects how good the ranking of predictions is, not just at one fixed cutoff. \\n\\nWhy They Are Important\\n\\nDifferent costs & risks: In many real‑world problems, false positives and false negatives have very different consequences. For example in disease detection, missing a sick patient can be worse than wrongly diagnosing a healthy one. Choosing metrics like recall or precision helps align with these real costs. \\n\\nClass imbalance: When one class is much more common than the other(s), accuracy can be misleading (a model that always predicts the majority class might have high accuracy but useless behavior). Metrics like F1, precision, recall, and ROC‑AUC give better insight under imbalance. \\n\\nModel comparison & tuning: They allow comparing different models or settings (thresholds, regularization, features) in a meaningful way. One model might have better precision but worse recall; metrics help decide which trade‑offs are acceptable. \\n\\nBusiness relevance: Ultimately, models often serve business or health or safety goals; metrics translate raw predictive performance into quantities easier to interpret by stakeholders: mistakes, risks, benefits. Choosing appropriate metrics ensures model evaluation ties back to what matters in practice.\\n\\n\\n\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "'''\n",
        "\n",
        "##Question 1:  What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "Logistic Regression is a statistical / machine‑learning method used to predict categorical outcomes, especially when there are two possible classes (binary classification). It estimates the probability that a given input belongs to one class rather than another (for example, “spam” vs “not spam”, “disease” vs “no disease”). Based on that probability, one can decide a threshold (often 0.5) and assign a class label. It uses features (input variables) to compute how they influence the likelihood of each class.\n",
        "\n",
        "In contrast, Linear Regression is used when the target/output is continuous (such as house prices, temperature, height). It models a direct linear relationship between input variables and the numerical output: given inputs, it predicts a value on a continuous scale.\n",
        "\n",
        "Key differences:\n",
        "\n",
        "Output type: Logistic gives probabilities / classes (categorical), Linear gives numerical values (continuous).\n",
        "\n",
        "Interpretation: In Linear Regression, the change in output is directly proportional to changes in input; in Logistic Regression, inputs affect the log‑odds or relative risk, hence indirectly influence the probability of class membership.\n",
        "\n",
        "Assumptions and model fitting: Linear Regression assumes the errors are normally distributed, constant variance (homoscedasticity), etc., and typically uses least squares methods. Logistic Regression does not assume the output is normally distributed; it uses methods like maximum likelihood estimation to find the best parameters.\n",
        "\n",
        "\n",
        "##Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "Purpose of the Sigmoid in Logistic Regression\n",
        "\n",
        "Mapping to Probability Values\n",
        "When the model computes a raw score (a weighted sum of features plus a bias), that result can be any real number — positive, negative, large, or small. The sigmoid transforms that into something between 0 and 1. That output can be interpreted as the probability that the input belongs to the positive class.\n",
        "\n",
        "Enabling Decision Making\n",
        "Once we have a probability, we can pick a threshold (commonly 0.5) to decide whether to assign class “yes/1” or “no/0.” Without the sigmoid, the raw score wouldn’t map cleanly into a probability, and we couldn’t as naturally choose such thresholds.\n",
        "\n",
        "Smooth Transition Around the Boundary\n",
        "The sigmoid gives a smooth, “S‑shaped” transition from low probability to high probability as the raw score shifts. That means small changes near the decision boundary (where the model is uncertain) lead to gradual change in output. This allows the model to learn in a stable way when changing its parameters.\n",
        "\n",
        "Suitability for Optimization\n",
        "Because the sigmoid is smooth and differentiable everywhere, it supports gradient‑based optimization. The model’s training process (e.g. maximizing likelihood or minimizing a loss) needs to know how output changes as parameters change. The sigmoid’s smoothness helps compute those gradients reliably.\n",
        "\n",
        "\n",
        "##Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Regularization in Logistic Regression is a technique used to reduce overfitting by constraining or penalizing the magnitude of the model’s parameters (coefficients). It helps the model generalize better to unseen data rather than just memorizing the training examples.\n",
        "\n",
        "Why Regularization Is Needed\n",
        "\n",
        "Models with many features or those that are very flexible can fit even random noise in the training data. That leads to high performance on training data but poor performance on new/unseen data. This is called overfitting.\n",
        "\n",
        "Regularization prevents the model from relying too heavily on any one feature or giving extremely large weights to some features. That reduces variance in model predictions.\n",
        "\n",
        "\n",
        "It improves stability: with regularization, small changes in training data or slight noise won’t cause wildly different parameter estimates. This makes the model more robust.\n",
        "\n",
        "How Regularization Works (Conceptually)\n",
        "\n",
        "Even without going into formulas:\n",
        "\n",
        "Introduce a penalty or constraint on large parameter values. The model then finds a balance between accurately classifying the training data and keeping its parameters “small” or “simple.”\n",
        "\n",
        "There are different styles:\n",
        "\n",
        "One type encourages sparse solutions (making some parameters zero → effectively ignoring less useful features)\n",
        "\n",
        "Another just “shrinks” all parameters somewhat toward simpler values without necessarily zeroing them out\n",
        "\n",
        "\n",
        "##Question 4: What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "\n",
        "Here are some common evaluation metrics for classification models, and why they matter — all without using equations:\n",
        "\n",
        "Common Metrics\n",
        "\n",
        "Accuracy\n",
        "Measures how often the model’s predictions are correct overall (both positive and negative). It is intuitive and widely used.\n",
        "\n",
        "Precision\n",
        "Of those cases the model predicts as positive, how many are truly positive. Useful when false alarms (false positives) are costly.\n",
        "\n",
        "Recall (Sensitivity)\n",
        "Of all actual positive cases, how many did the model correctly identify. Important when missing positive cases is more serious.\n",
        "\n",
        "F1‑Score\n",
        "A harmonic balancing of precision and recall. It gives a single score that reflects both, helpful especially when classes are imbalanced or when you require a trade‑off between false positives and false negatives.\n",
        "\n",
        "ROC‑AUC (Receiver Operating Characteristic – Area Under Curve)\n",
        "Considers how well the model distinguishes positive and negative classes across different thresholds. It reflects how good the ranking of predictions is, not just at one fixed cutoff.\n",
        "\n",
        "Why They Are Important\n",
        "\n",
        "Different costs & risks: In many real‑world problems, false positives and false negatives have very different consequences. For example in disease detection, missing a sick patient can be worse than wrongly diagnosing a healthy one. Choosing metrics like recall or precision helps align with these real costs.\n",
        "\n",
        "Class imbalance: When one class is much more common than the other(s), accuracy can be misleading (a model that always predicts the majority class might have high accuracy but useless behavior). Metrics like F1, precision, recall, and ROC‑AUC give better insight under imbalance.\n",
        "\n",
        "Model comparison & tuning: They allow comparing different models or settings (thresholds, regularization, features) in a meaningful way. One model might have better precision but worse recall; metrics help decide which trade‑offs are acceptable.\n",
        "\n",
        "Business relevance: Ultimately, models often serve business or health or safety goals; metrics translate raw predictive performance into quantities easier to interpret by stakeholders: mistakes, risks, benefits. Choosing appropriate metrics ensures model evaluation ties back to what matters in practice.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "#splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "#(Use Dataset from sklearn package)\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def main():\n",
        "    # Load Iris dataset\n",
        "    iris = load_iris(as_frame=True)\n",
        "    df = iris.frame  # pandas DataFrame including feature columns + target\n",
        "    X = df.drop(columns=[\"target\"])\n",
        "    y = df[\"target\"]\n",
        "\n",
        "    # Split into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.25, random_state=0, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train logistic regression\n",
        "    model = LogisticRegression(max_iter=200)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Iris dataset — accuracy: {acc:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUNGAz10kKWL",
        "outputId": "8ff63e32-a6a4-4a09-c9cf-6f77bdd8f461"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iris dataset — accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 6:  Write a Python program to train a Logistic Regression model using L2\n",
        "#regularization (Ridge) and print the model coefficients and accuracy.\n",
        "#(Use Dataset from sklearn package)\n",
        "\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def main():\n",
        "    # Load a built‑in dataset (multiclass)\n",
        "    data = load_wine()\n",
        "    X = data.data\n",
        "    y = data.target\n",
        "\n",
        "    # It is often good to standardize features when using regularization\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split into train and test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.2, random_state=0, stratify=y\n",
        "    )\n",
        "\n",
        "    # Train Logistic Regression with L2 regularization\n",
        "    # In sklearn, penalty='l2' is default, so you can also use that explicitly\n",
        "    model = LogisticRegression(\n",
        "        penalty='l2',\n",
        "        C=1.0,            # inverse of regularization strength\n",
        "        solver='lbfgs',   # works well for multiclass\n",
        "        max_iter=200\n",
        "    )\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Print model coefficients (one set per class in multiclass case)\n",
        "    print(\"Intercepts for each class:\")\n",
        "    print(model.intercept_)\n",
        "    print(\"Coefficients for each feature and class:\")\n",
        "    print(model.coef_)\n",
        "\n",
        "    # Predict and compute accuracy\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy on test set: {acc:.2f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB9TNdgJl0RJ",
        "outputId": "251f5cf7-6273-456f-af30-0e26c1937bd7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercepts for each class:\n",
            "[ 0.38558157  0.76600918 -1.15159075]\n",
            "Coefficients for each feature and class:\n",
            "[[ 0.76902723  0.22076332  0.41423956 -0.80212986  0.10545623  0.19121707\n",
            "   0.66221979 -0.16873448  0.2017629   0.11575909  0.19514148  0.61414432\n",
            "   1.0467281 ]\n",
            " [-0.96407141 -0.43735909 -0.82801935  0.58153442 -0.14249886  0.06443012\n",
            "   0.33515281  0.14281946  0.20936102 -0.9554117   0.58673576  0.12245181\n",
            "  -1.09535428]\n",
            " [ 0.19504417  0.21659577  0.41377979  0.22059543  0.03704263 -0.25564719\n",
            "  -0.9973726   0.02591502 -0.41112391  0.83965261 -0.78187724 -0.73659613\n",
            "   0.04862618]]\n",
            "Accuracy on test set: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "#classification using multi_class='ovr' and print the classification report.\n",
        "#(Use Dataset from sklearn package)\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "def main():\n",
        "    # Load the Iris dataset\n",
        "    iris = load_iris()\n",
        "    X = iris.data\n",
        "    y = iris.target\n",
        "    class_names = iris.target_names\n",
        "\n",
        "    # Split into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.3, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Instantiate Logistic Regression with one‑vs‑rest multiclass strategy\n",
        "    model = LogisticRegression(multi_class='ovr', solver='liblinear', max_iter=200, random_state=42)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Print accuracy\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {acc:.2f}\")\n",
        "\n",
        "    # Print classification report (precision, recall, f1 for each class)\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=class_names))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-TivwMwqTDt",
        "outputId": "8c7e0590-8f2f-4070-ca79-9461109f048b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.91\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        15\n",
            "  versicolor       1.00      0.73      0.85        15\n",
            "   virginica       0.79      1.00      0.88        15\n",
            "\n",
            "    accuracy                           0.91        45\n",
            "   macro avg       0.93      0.91      0.91        45\n",
            "weighted avg       0.93      0.91      0.91        45\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "#hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "#accuracy.\n",
        "#(Use Dataset from sklearn package)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the Logistic Regression model\n",
        "log_reg = LogisticRegression(max_iter=10000)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': np.logspace(-4, 4, 20),  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],     # Regularization type\n",
        "    'solver': ['liblinear', 'saga']  # Solvers that support both penalties\n",
        "}\n",
        "\n",
        "# Set up GridSearchCV\n",
        "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "\n",
        "# Fit the model\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Print the best parameters and validation accuracy\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "print(f\"Best Cross-Validation Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "test_accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lsj3PVN7s_gl",
        "outputId": "f040c2eb-a17d-4fbb-d517-6b62d65d55ca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n",
            "Best Parameters: {'C': np.float64(1.623776739188721), 'penalty': 'l1', 'solver': 'saga'}\n",
            "Best Cross-Validation Accuracy: 0.9583\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to standardize the features before training Logistic Regression and compare the model's accuracy with and without scaling. (Use Dataset from sklearn package) (Include your Python code and output in the code box below.)\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Digits dataset\n",
        "digits = load_digits()\n",
        "X = digits.data\n",
        "y = digits.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=10000, random_state=42)\n",
        "\n",
        "# Train and evaluate the model without scaling\n",
        "model.fit(X_train, y_train)\n",
        "y_pred_no_scaling = model.predict(X_test)\n",
        "accuracy_no_scaling = accuracy_score(y_test, y_pred_no_scaling)\n",
        "\n",
        "# Apply Standard Scaling to the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train and evaluate the model with scaling\n",
        "model.fit(X_train_scaled, y_train)\n",
        "y_pred_scaled = model.predict(X_test_scaled)\n",
        "accuracy_scaled = accuracy_score(y_test, y_pred_scaled)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy without scaling: {accuracy_no_scaling:.4f}\")\n",
        "print(f\"Accuracy with scaling: {accuracy_scaled:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdwFBtH-tLC3",
        "outputId": "9c1cafa1-78ec-4bd1-fc50-d60b45b64ca1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 0.9622\n",
            "Accuracy with scaling: 0.9778\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Question 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\n",
        "\n",
        "To build a robust Logistic Regression model for predicting customer responses in an imbalanced e-commerce dataset (5% responders), I would adopt a comprehensive approach encompassing data handling, feature scaling, class balancing, hyperparameter tuning, and model evaluation.\n",
        "\n",
        "1. Data Handling\n",
        "\n",
        "Missing Values: Impute missing data using median imputation for numerical features and mode imputation for categorical features.\n",
        "\n",
        "Categorical Encoding: Apply one-hot encoding to nominal variables and ordinal encoding to ordinal variables.\n",
        "\n",
        "Feature Engineering: Create interaction terms and aggregate features to capture non-linear relationships.\n",
        "\n",
        "2. Class Balancing\n",
        "\n",
        "Class Weights: Assign higher weights to the minority class during model training to penalize misclassifications of responders more heavily.\n",
        "\n",
        "SMOTE: Implement the Synthetic Minority Over-sampling Technique to generate synthetic samples for the minority class, enhancing model sensitivity to rare events.\n",
        "\n",
        "3. Feature Scaling\n",
        "\n",
        "Standardization: Use StandardScaler to standardize numerical features, ensuring they have a mean of 0 and a standard deviation of 1. This is crucial for models sensitive to feature scales.\n",
        "\n",
        "\n",
        "4. Hyperparameter Tuning\n",
        "\n",
        "GridSearchCV: Employ GridSearchCV to tune hyperparameters such as the regularization strength (C) and penalty type (l1 or l2). Use metrics like F1-score or AUC-ROC for evaluation to better capture performance on imbalanced data.\n",
        "\n",
        "\n",
        "5. Model Evaluation\n",
        "\n",
        "Metrics: Focus on precision, recall, F1-score, and AUC-ROC to assess model performance, as accuracy is misleading in imbalanced datasets.\n",
        "\n",
        "Confusion Matrix: Analyze the confusion matrix to understand misclassifications and adjust thresholds accordingly.\n",
        "\n",
        "6. Business Integration\n",
        "\n",
        "Threshold Adjustment: Set a decision threshold that balances precision and recall, aligning with business objectives.\n",
        "\n",
        "Cost-Benefit Analysis: Evaluate the model's performance in terms of return on investment, considering the cost of targeting non-responders.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "2J4FSJkfwBn3",
        "outputId": "16091924-bd14-4883-9f88-7b582df17a76"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nQuestion 10: Imagine you are working at an e-commerce company that wants to predict which customers will respond to a marketing campaign. Given an imbalanced dataset (only 5% of customers respond), describe the approach you’d take to build a Logistic Regression model — including data handling, feature scaling, balancing classes, hyperparameter tuning, and evaluating the model for this real-world business use case.\\n\\nTo build a robust Logistic Regression model for predicting customer responses in an imbalanced e-commerce dataset (5% responders), I would adopt a comprehensive approach encompassing data handling, feature scaling, class balancing, hyperparameter tuning, and model evaluation.\\n\\n1. Data Handling\\n\\nMissing Values: Impute missing data using median imputation for numerical features and mode imputation for categorical features.\\n\\nCategorical Encoding: Apply one-hot encoding to nominal variables and ordinal encoding to ordinal variables.\\n\\nFeature Engineering: Create interaction terms and aggregate features to capture non-linear relationships.\\n\\n2. Class Balancing\\n\\nClass Weights: Assign higher weights to the minority class during model training to penalize misclassifications of responders more heavily.\\n\\nSMOTE: Implement the Synthetic Minority Over-sampling Technique to generate synthetic samples for the minority class, enhancing model sensitivity to rare events. \\n\\n3. Feature Scaling\\n\\nStandardization: Use StandardScaler to standardize numerical features, ensuring they have a mean of 0 and a standard deviation of 1. This is crucial for models sensitive to feature scales. \\n\\n\\n4. Hyperparameter Tuning\\n\\nGridSearchCV: Employ GridSearchCV to tune hyperparameters such as the regularization strength (C) and penalty type (l1 or l2). Use metrics like F1-score or AUC-ROC for evaluation to better capture performance on imbalanced data. \\n\\n\\n5. Model Evaluation\\n\\nMetrics: Focus on precision, recall, F1-score, and AUC-ROC to assess model performance, as accuracy is misleading in imbalanced datasets.\\n\\nConfusion Matrix: Analyze the confusion matrix to understand misclassifications and adjust thresholds accordingly.\\n\\n6. Business Integration\\n\\nThreshold Adjustment: Set a decision threshold that balances precision and recall, aligning with business objectives.\\n\\nCost-Benefit Analysis: Evaluate the model's performance in terms of return on investment, considering the cost of targeting non-responders.\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G6BBeG-Lwesl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}